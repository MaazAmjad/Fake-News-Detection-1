{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Cosine Feature Extraction and Random Forest Classifier\n",
    "\n",
    "The following sources were used to construct this Jupyter Notebook:\n",
    "\n",
    "* [Numpy: Dot Multiplication, Vstack, Hstack, Flatten](https://www.youtube.com/watch?v=nkO6bmp511M)\n",
    "* [Scikit Learn TF-IDF Feature Extraction and Latent Semantic Analysis](https://www.youtube.com/watch?v=BJ0MnawUpaU)\n",
    "* [Fake News Challenge TF-IDF Baseline](https://github.com/gmyrianthous/fakenewschallenge/blob/master/baseline.py)\n",
    "* [Python TF-IDF Algorithm Built From Scratch](https://www.youtube.com/watch?v=hXNbFNCgPfY)\n",
    "* [Theory Behind TF-IDF](https://www.youtube.com/watch?v=4vT4fzjkGCQ)\n",
    "* [Plotting Classifier Boundaries](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 (default, Jan  6 2018, 11:51:59) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "#Import all required modules\n",
    "\n",
    "#For parsing and visualizing data\n",
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "\n",
    "#For visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For processing data\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Feature Engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n",
    "import baseline_features\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#For scoring\n",
    "from sklearn.metrics import accuracy_score\n",
    "import score #Score used in competition\n",
    "\n",
    "#Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Reloading modules that have been updated\n",
    "#import importlib\n",
    "#importlib.reload(baseline_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data from CSV file and create a dataframe\n",
    "def create_dataframe(filename):\n",
    "    #Read file into a pandas dataframe\n",
    "    df = pd.read_csv(filename)\n",
    "    #Remove white space in column names\n",
    "    df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body_ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframes for both training and testing sets\n",
    "train_df_tmp = create_dataframe('train_stances.csv')\n",
    "train_bodies_df = create_dataframe('train_bodies.csv')\n",
    "\n",
    "test_df_tmp = create_dataframe('competition_test_stances.csv')\n",
    "test_bodies_df = create_dataframe('test_bodies.csv')\n",
    "\n",
    "train_df_tmp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Dataframes on Body_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df_tmp,\n",
    "                 train_bodies_df[['Body_ID', 'articleBody']],\n",
    "                 on='Body_ID')\n",
    "\n",
    "test_df = pd.merge(test_df_tmp,\n",
    "                 test_bodies_df[['Body_ID', 'articleBody']],\n",
    "                 on='Body_ID')\n",
    "\n",
    "train_df = train_df.rename(columns={'articleBody': 'Body_Text'})\n",
    "test_df = test_df.rename(columns={'articleBody': 'Body_Text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Body_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>Apple to keep gold Watch Editions in special i...</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>Apple installing safes in-store to protect gol...</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n",
       "      <td>1</td>\n",
       "      <td>agree</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7306</th>\n",
       "      <td>Apple Stores to Keep Gold “Edition” Apple Watc...</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7307</th>\n",
       "      <td>South Korean woman's hair 'eaten' by robot vac...</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Headline  Body_ID     Stance  \\\n",
       "7305  Apple to keep gold Watch Editions in special i...        1  unrelated   \n",
       "7303  Apple installing safes in-store to protect gol...        1  unrelated   \n",
       "7304  El-Sisi denies claims he'll give Sinai land to...        1      agree   \n",
       "7306  Apple Stores to Keep Gold “Edition” Apple Watc...        1  unrelated   \n",
       "7307  South Korean woman's hair 'eaten' by robot vac...        1  unrelated   \n",
       "\n",
       "                                              Body_Text  \n",
       "7305  Al-Sisi has denied Israeli reports stating tha...  \n",
       "7303  Al-Sisi has denied Israeli reports stating tha...  \n",
       "7304  Al-Sisi has denied Israeli reports stating tha...  \n",
       "7306  Al-Sisi has denied Israeli reports stating tha...  \n",
       "7307  Al-Sisi has denied Israeli reports stating tha...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by=['Body_ID']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body_ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Body_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41651</th>\n",
       "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41657</th>\n",
       "      <td>Italian catches huge wels catfish; is it a rec...</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41658</th>\n",
       "      <td>Not coming to a store near you: The pumpkin sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41659</th>\n",
       "      <td>One gunman killed in shooting on Parliament Hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41660</th>\n",
       "      <td>Soldier shot at war memorial in Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Headline  Body_ID     Stance  \\\n",
       "41651  Soldier shot, Parliament locked down after gun...        0  unrelated   \n",
       "41657  Italian catches huge wels catfish; is it a rec...        0  unrelated   \n",
       "41658  Not coming to a store near you: The pumpkin sp...        0  unrelated   \n",
       "41659  One gunman killed in shooting on Parliament Hi...        0  unrelated   \n",
       "41660             Soldier shot at war memorial in Canada        0  unrelated   \n",
       "\n",
       "                                               Body_Text  \n",
       "41651  A small meteorite crashed into a wooded area i...  \n",
       "41657  A small meteorite crashed into a wooded area i...  \n",
       "41658  A small meteorite crashed into a wooded area i...  \n",
       "41659  A small meteorite crashed into a wooded area i...  \n",
       "41660  A small meteorite crashed into a wooded area i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by=['Body_ID']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Body_Text  \\\n",
      "14020  A former PGA Tour player claims Tiger Woods ha...   \n",
      "12430  KANSAS CITY, Mo. - Kansas City health official...   \n",
      "44352  Warning: graphic image below\\n\\nA 22-year-old ...   \n",
      "36868  Ottawa shooting video shown by police\\n\\nThe R...   \n",
      "30213  British man suspected of appearing in videos o...   \n",
      "2948   While Apple announced that the base model of i...   \n",
      "18034  First lady Michelle Obama’s face was reportedl...   \n",
      "28735  A touching tribute to the victims of the Charl...   \n",
      "25686  A baseball cap and a portrait of Michael Brown...   \n",
      "38318  A rumor on Tuesday claims Apple's upcoming App...   \n",
      "33269  The British Islamic State militant known as \"J...   \n",
      "31956  Two Aussie mates had to be talked out of the g...   \n",
      "47785  The reported ceasefire between the Nigerian go...   \n",
      "47489  KANSAS CITY, MO (KCTV) -\\nA man rushed to a Ka...   \n",
      "45092  Days before Christmas, Internet prankster Josh...   \n",
      "8462   Judd Nelson rebuffs Internet rumors that he di...   \n",
      "44652  Gill Rosenberg, 31,said last week on Facebook ...   \n",
      "7924   U.S. Rep. Duncan Hunter this week declared ter...   \n",
      "37990  A video of an airport worker stripping naked t...   \n",
      "26873  A video posted by ISIL terrorists in Iraq purp...   \n",
      "16627  GAZA, Feb. 22 (Xinhua) -- A Palestinian minist...   \n",
      "41500  Twitter is hopping right now about how Saudi T...   \n",
      "22400  FORT DEVENS, Massachusetts -\\n\\nInfamous Bosto...   \n",
      "32893  Only in Detroit? Holy stolen Batmobile, Batman...   \n",
      "22451  FORT DEVENS, Massachusetts -\\n\\nInfamous Bosto...   \n",
      "7872   A picture of a letter to parents from a box of...   \n",
      "24321  Is Fidel Castro dead? Yes, a man named “Fidel ...   \n",
      "30037  Big Bank Hank, a member of the early hip-hop g...   \n",
      "10594  Planetary Alignment On Jan 4, 2015 Will Decrea...   \n",
      "29103  In quite recent news, J J Abrams has reportedl...   \n",
      "...                                                  ...   \n",
      "189    (Reuters) - A Canadian soldier was shot at the...   \n",
      "2747   NEW YORK — Pope Francis has given hope to gays...   \n",
      "18431  Jose Canseco was injured in an accidental shoo...   \n",
      "18942  Nigeria has agreed a truce with militant Islam...   \n",
      "25658  A baseball cap and a portrait of Michael Brown...   \n",
      "41434  The proposal went off with a different kind of...   \n",
      "27480  Boston - So lately, tongues have been wagging ...   \n",
      "6396   Young North Korean dictator Kim Jong Un’s heal...   \n",
      "28693  A touching tribute to the victims of the Charl...   \n",
      "19769  Online retail giant Amazon.com Inc. AMZN -1.98...   \n",
      "17568  James Foley went missing in November 2012\\n\\nA...   \n",
      "39188  When a report went viral that NBC meteorologis...   \n",
      "37819  Islamic State brutes fed a distraught woman se...   \n",
      "5311   A disturbing video posted online appears to sh...   \n",
      "2433   Pentagon investigating claims but admits one l...   \n",
      "769    ABUJA, Nigeria — The leader of Nigeria's Islam...   \n",
      "1685   Dino Ferrari hooked the whopper wels catfish, ...   \n",
      "41090  Christian Bale will slip into a mock turtlenec...   \n",
      "16023  Doctor in besieged Syrian town reports arrival...   \n",
      "44131  In a video released late Friday night, the lea...   \n",
      "47191  LAGOS — A wave of violence hours after Nigeria...   \n",
      "21962  A Texas National Guard soldier scans the Mexic...   \n",
      "37194  (CNN) -- Could a newly released audio provide ...   \n",
      "16850  Piper Jaffray’s Gene Munster has issued a new ...   \n",
      "6265   The Force may be with us a little sooner than ...   \n",
      "11284  What do you do when your twin is having sex wi...   \n",
      "44732  Wanted: Islamic State group chief Abu Bakr al-...   \n",
      "38158  Homeland Security Secretary Jeh Johnson is pus...   \n",
      "860    You want a gold Apple Watch, you say? Then it'...   \n",
      "15795  It sure looks like Weather Channel meteorologi...   \n",
      "\n",
      "                                                Headline  \n",
      "14020                 Setting the record straight on tor  \n",
      "12430  Return of the Mac: Seth Rogen in talks to star...  \n",
      "44352  One of 'Taliban Five' in Bowe Bergdahl swap al...  \n",
      "36868  Alleged Ottawa gunman: What we know so far abo...  \n",
      "30213  Sorry, Everyone: Durex Is Unfortunately Not Ma...  \n",
      "2948   Strange mark turns out to be tropical spider b...  \n",
      "18034  BREAKING NEWS: British-born U.S. photojournali...  \n",
      "28735  ISIS beheads American photo-journalist James W...  \n",
      "25686  In Moscow, police are looking for a felon, cut...  \n",
      "38318  Oscar winner Christian Bale to play Steve Jobs...  \n",
      "33269  Islamic State killer 'Jihadi John' named as Mo...  \n",
      "31956  Iraqi media: ISIS militants have contracted Ebola  \n",
      "47785  Insurgents killed in Nigeria despite alleged t...  \n",
      "47489  Hospital: Man not being treated for Ebola in K...  \n",
      "45092  SEE IT: California homeless man uses $100 gift...  \n",
      "8462   Low-level marijuana possession could soon land...  \n",
      "44652  Ottawa investigates reports that Isis has capt...  \n",
      "7924   NEWS/ You'll Never Guess How a Homeless Man Sp...  \n",
      "37990  Ferguson riots: audio may have captured Michae...  \n",
      "26873  Norfolk Man Pays £300 For His Constipated Gold...  \n",
      "16627  Attorney: New audio reveals pause in gunfire w...  \n",
      "41500  CNN Plays Alleged Audiotape of Michael Brown S...  \n",
      "22400  GOP Rep: ‘At Least Ten ISIS Fighters Have Been...  \n",
      "32893  Mexico Says Students Not Among Dead in Mass Grave  \n",
      "22451  Judicial Watch's Farrell: ISIS Terrorists Did ...  \n",
      "7872   Gill Rosenberg, Canadian-Israeli Woman Feared ...  \n",
      "24321  Op-Ed: Hoax – Priest who never existed claims ...  \n",
      "30037  Reports: Big Bank Hank of pioneering rap group...  \n",
      "10594  Is the Alleged Audio of the Gunshots That Kill...  \n",
      "29103  KFC Locations In Colorado To Begin Selling Mar...  \n",
      "...                                                  ...  \n",
      "189    Tim Cook Reportedly Reveals Apple Watch Waterp...  \n",
      "2747   Small meteorite strikes Nicaragua, government ...  \n",
      "18431  Nigeria: hopes for return of kidnapped schoolg...  \n",
      "18942  Kidnapped Nigerian schoolgirls: Government cla...  \n",
      "25658      Batmobile stolen in Detroit? Good one, joker!  \n",
      "41434  Seven girls fall pregnant after five day schoo...  \n",
      "27480  This Letter To Parents From A 1970s Lego Set C...  \n",
      "6396   SEE IT: NBC meteorologist Mike Seidel appears ...  \n",
      "28693  James Wright Foley, Kidnapped Journalist, Appa...  \n",
      "19769  Hundreds mourn the 'death' of Fidel Castro aft...  \n",
      "17568  ISIS Reportedly Beheads American Photojournali...  \n",
      "39188  Cameron vows to hunt down IS 'monsters' after ...  \n",
      "37819  North Korean leader Kim Jong Un had ankle surg...  \n",
      "5311   Obama Denounces James Foley's Execution: 'Toda...  \n",
      "2433   Islamic State claims it executed American phot...  \n",
      "769    DNA tests prove Lebanon IS holding ISIS chief ...  \n",
      "1685   ‘Feminist’ says she aborted baby because it wa...  \n",
      "41090  High school student scores $72M playing the st...  \n",
      "16023    Iraqi social-media rumors claim IS leader slain  \n",
      "44131  More than 200 kidnapped Nigerian girls to be r...  \n",
      "47191  Insurgents killed in Nigeria despite alleged t...  \n",
      "21962  This Is Why Rumors That ISIS Is Crossing The B...  \n",
      "37194  Catholic Priest Dies for 48 Minutes, Comes Bac...  \n",
      "16850  ISIS Video: America’s Air Dropped Weapons Now ...  \n",
      "6265   Islamist terrorists Jabhat Ansar al-Deen tweet...  \n",
      "11284  Seth Rogen to play Steve Wozniak alongside Chr...  \n",
      "44732  Graffiti Artist Banksy Arrested In London; Ide...  \n",
      "38158  Mexico Says Missing Students Not Found In Firs...  \n",
      "860    Congressman: ‘At least 10 ISIS fighters’ caugh...  \n",
      "15795  Kim Jong-un relying on ‘cobra wine’ after prob...  \n",
      "\n",
      "[29983 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Split training data into training and validation set\n",
    "train_df, validate_df, train_labels, validate_labels = train_test_split(train_df[['Body_Text','Headline']], train_df['Stance'], test_size=.4, random_state=42)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Scikit Learn TFIDF Feature Extraction Algorithm\n",
    "body_text_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, stop_words='english',max_features=1024)\n",
    "headline_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, stop_words='english',max_features=1024)\n",
    "\n",
    "#Create vocabulary based on training data\n",
    "train_body_tfidf = body_text_vectorizer.fit_transform(train_df['Body_Text'])\n",
    "train_headline_tfidf = headline_vectorizer.fit_transform(train_df['Headline'])\n",
    "\n",
    "#Create vocabulary based on validation data\n",
    "validate_body_tfidf = body_text_vectorizer.transform(validate_df['Body_Text'])\n",
    "validate_headline_tfidf = headline_vectorizer.transform(validate_df['Headline'])\n",
    "\n",
    "#Use vocabulary for testing data\n",
    "test_body_tfidf = body_text_vectorizer.transform(test_df['Body_Text'])\n",
    "test_headline_tfidf = headline_vectorizer.transform(test_df['Headline']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "def get_cosine_similarity(body_tfidf,headline_tfidf):\n",
    "    cosine_features = []\n",
    "    #len body_tfidf = len headline_tfidf\n",
    "    for i in tqdm(range(body_tfidf.shape[0])):\n",
    "        cosine_features.append(cosine_similarity((body_tfidf.A[0].reshape(1,-1)),(headline_tfidf.A[0].reshape(1,-1)))[0][0])\n",
    "    return np.array(cosine_features).reshape(body_tfidf.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Leave this commented out unless you are re-calculating the cosine similarity\n",
    "#which can be found in the pickle files labeled: \n",
    "#train_cosine_features.p and test_cosine_features.p\n",
    "\n",
    "#Train data\n",
    "#train_cosine_features = get_cosine_similarity(train_body_tfidf,train_headline_tfidf)\n",
    "\n",
    "#Validate data\n",
    "#validate_cosine_features = get_cosine_similarity(validate_body_tfidf,validate_headline_tfidf)\n",
    "\n",
    "#Test data\n",
    "#test_cosine_features = get_cosine_similarity(test_body_tfidf,test_headline_tfidf)\n",
    "\n",
    "#pickle.dump(train_cosine_features,open('train_cosine_features.p','wb'))\n",
    "#pickle.dump(train_cosine_features,open('validate_cosine_features.p','wb'))\n",
    "#pickle.dump(test_cosine_features,open('test_cosine_features.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cosine_features = pickle.load(open('train_cosine_features.p','rb'))\n",
    "validate_cosine_features = pickle.load(open('validate_cosine_features.p','rb'))\n",
    "test_cosine_features = pickle.load(open('test_cosine_features.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Selected Features (Baseline Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [04:05, 203.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train_hand_features = baseline_features.hand_features(train_df['Headline'],train_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19989it [02:40, 124.45it/s]\n"
     ]
    }
   ],
   "source": [
    "validate_hand_features = baseline_features.hand_features(validate_df['Headline'],validate_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25413it [02:01, 209.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test_hand_features = baseline_features.hand_features(test_df['Headline'],test_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_hand_features = np.array(train_hand_features)\n",
    "validate_hand_features = np.array(validate_hand_features)\n",
    "test_hand_features = np.array(test_hand_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Overlap Features (Baseline Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [03:25, 243.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train_overlap_features = baseline_features.word_overlap_features(train_df['Headline'],train_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19989it [02:07, 156.18it/s]\n"
     ]
    }
   ],
   "source": [
    "validate_overlap_features = baseline_features.word_overlap_features(validate_df['Headline'],validate_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25413it [01:44, 243.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_overlap_features = baseline_features.word_overlap_features(test_df['Headline'],test_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_overlap_features = np.array(train_overlap_features)\n",
    "validate_overlap_features = np.array(validate_overlap_features)\n",
    "test_overlap_features = np.array(test_overlap_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity Features (Baseline Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [03:37, 229.53it/s]\n"
     ]
    }
   ],
   "source": [
    "train_polarity_features = baseline_features.polarity_features(train_df['Headline'],train_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19989it [02:16, 146.16it/s]\n"
     ]
    }
   ],
   "source": [
    "validate_polarity_features = baseline_features.polarity_features(validate_df['Headline'],validate_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25413it [01:41, 249.67it/s]\n"
     ]
    }
   ],
   "source": [
    "test_polarity_features = baseline_features.polarity_features(test_df['Headline'],test_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_polarity_features = np.array(train_polarity_features)\n",
    "validate_polarity_features = np.array(validate_polarity_features)\n",
    "test_polarity_features = np.array(test_polarity_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refuting Features (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49972it [00:12, 3917.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_refuting_features = baseline_features.refuting_features(train_df['Headline'],train_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19989it [00:07, 2605.04it/s]\n"
     ]
    }
   ],
   "source": [
    "validate_refuting_features = baseline_features.refuting_features(validate_df['Headline'],validate_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25413it [00:06, 3646.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_refuting_features = baseline_features.refuting_features(test_df['Headline'],test_df['Body_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_refuting_features = np.array(train_refuting_features)\n",
    "validate_refuting_features = np.array(validate_refuting_features)\n",
    "test_refuting_features = np.array(test_refuting_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = hstack([\n",
    "                            train_body_tfidf,\n",
    "                            train_headline_tfidf,\n",
    "                            train_hand_features,\n",
    "                            train_cosine_features,\n",
    "                            train_overlap_features,\n",
    "                            train_polarity_features,\n",
    "                            train_refuting_features\n",
    "    \n",
    "                        ])\n",
    "validate_features = hstack([\n",
    "                            validate_body_tfidf,\n",
    "                            validate_headline_tfidf,\n",
    "                            validate_hand_features,\n",
    "                            validate_cosine_features,\n",
    "                            validate_overlap_features,\n",
    "                            validate_polarity_features,\n",
    "                            validate_refuting_features\n",
    "                            \n",
    "                        ])\n",
    "test_features = hstack([\n",
    "                            test_body_tfidf,\n",
    "                            test_headline_tfidf,\n",
    "                            test_hand_features,\n",
    "                            test_cosine_features,\n",
    "                            test_overlap_features,\n",
    "                            test_polarity_features,\n",
    "                            test_refuting_features\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We already have train_labels and validate_labels from before\n",
    "test_labels = list(test_df['Stance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classifiers and Score Validation Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    724    |     2     |    823    |    354    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    198    |     2     |    234    |    263    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    797    |     4     |   2874    |    789    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    61     |     3     |    460    |   17825   |\n",
      "-------------------------------------------------------------\n",
      "Score: 8570.75 out of 11651.25\t(73.56077674069306%)\n",
      "73.56077674069306\n",
      "Multinomial Naive Bayes\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |   1000    |    12     |    637    |    254    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    307    |     7     |    180    |    203    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |   1087    |    26     |   2742    |    609    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    278    |     3     |    695    |   17373   |\n",
      "-------------------------------------------------------------\n",
      "Score: 8654.5 out of 11651.25\t(74.27958373565068%)\n",
      "74.27958373565068\n",
      "Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       48816.3396           10.24m\n",
      "         2       43640.0130            9.78m\n",
      "         3       39455.1412            9.22m\n",
      "         4       36026.3939            8.65m\n",
      "         5       33187.5501            8.42m\n",
      "         6       30797.4296            8.23m\n",
      "         7       28796.7565            8.05m\n",
      "         8       27098.6968            7.99m\n",
      "         9       25624.8874            7.85m\n",
      "        10       24352.2854            7.75m\n",
      "        20       18048.8484            6.90m\n",
      "        30       15745.4552            6.35m\n",
      "        40       14473.8212            6.05m\n",
      "        50       13638.6263            5.61m\n",
      "        60       12987.0063            5.16m\n",
      "        70       12422.6624            4.79m\n",
      "        80       11956.5402            4.39m\n",
      "        90       11543.0370            4.06m\n",
      "       100       11197.8093            3.65m\n",
      "       200        8751.9327            0.00s\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    651    |     1     |    925    |    326    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    172    |     1     |    265    |    259    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    457    |     3     |   3289    |    715    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    25     |     0     |    320    |   18004   |\n",
      "-------------------------------------------------------------\n",
      "Score: 8897.75 out of 11651.25\t(76.36734255981118%)\n",
      "76.36734255981118\n",
      "K Nearest Neighbors\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f9897aa6fdc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 dist = pairwise_distances(X, self._fit_X, 'euclidean',\n\u001b[0;32m--> 357\u001b[0;31m                                           n_jobs=n_jobs, squared=True)\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 dist = pairwise_distances(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Special case to avoid picklability checks in delayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mYY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matmat_pass2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = [\"Random Forest\", \"Multinomial Naive Bayes\", \"Gradient Boosting\",\"K Nearest Neighbors\",\"Linear SVM\", \"Decision Tree\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=10),\n",
    "    MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
    "    GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True),\n",
    "    KNeighborsClassifier(4),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    LogisticRegression(C=1e5)\n",
    "]\n",
    "\n",
    "for n, clf in zip(names, classifiers):\n",
    "    print(n)\n",
    "    y_pred = clf.fit(train_features,train_labels).predict(validate_features)\n",
    "    print(score.report_score(test_labels, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classifiers and Score Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is how well we would have scored in the actual competition\n",
    "names = [\"Random Forest\", \"Multinomial Naive Bayes\", \"Gradient Boosting\",\"K Nearest Neighbors\",\"Linear SVM\", \"Decision Tree\", \"Logistic Regression\"]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=10),\n",
    "    MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
    "    GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True),\n",
    "    KNeighborsClassifier(4),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    LogisticRegression(C=1e5)\n",
    "]\n",
    "\n",
    "for n, clf in zip(names, classifiers):\n",
    "    print(n)\n",
    "    y_pred = clf.fit(train_features,train_labels).predict(validate_features)\n",
    "    print(score.report_score(test_labels, y_pred))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
